{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RealGIS-creator/scripts_realgis_banistmo_2025/blob/main/preparacion_datossucursales.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def remove_special_chars_but_keep_accents(text):\n",
        "\n",
        "    text = re.sub(r'[^\\w\\sáéíóúÁÉÍÓÚñÑ]', '', text, flags=re.UNICODE)\n",
        "    return text.upper()\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv('/content/ACTUALIZAR_SEGUNDA_ENTREGA.csv', encoding='utf-8', on_bad_lines='warn')\n",
        "except UnicodeDecodeError:\n",
        "    try:\n",
        "        df = pd.read_csv('ACTUALIZAR_SEGUNDA_ENTREGA.csv', encoding='latin-1', on_bad_lines='warn')\n",
        "    except UnicodeDecodeError:\n",
        "        df = pd.read_csv('ACTUALIZAR_SEGUNDA_ENTREGA.csv', encoding='ISO-8859-1', on_bad_lines='warn')\n",
        "\n",
        "\n",
        "df.columns = [''.join(filter(str.isalnum, col)) for col in df.columns]\n",
        "\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        df[col] = df[col].astype(str).apply(remove_special_chars_but_keep_accents)\n",
        "        df[col] = df[col].replace('NAN', '', regex=False)\n",
        "\n",
        "if 'RUC' in df.columns:\n",
        "    split_ruc = df['RUC'].str.split(' ', expand=True, n=3)\n",
        "    num_cols = split_ruc.shape[1]\n",
        "    ruc_cols = [f'RUC_Part{i+1}' for i in range(num_cols)]\n",
        "    df[ruc_cols] = split_ruc\n",
        "\n",
        "\n",
        "df.to_csv('/content/DatosSucursalesLimpios.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "mrCX0tBAm_au",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Cargar archivos\n",
        "acreditados_df = pd.read_csv('ACREDITADOS.csv')\n",
        "sucursales_df = pd.read_csv('/content/DatosSucursalesLimpios.csv')\n",
        "\n",
        "# Normalizar identificadores\n",
        "acreditados_df['acreditadoidenti'] = acreditados_df['acreditadoidenti'].astype(str).str.replace('-', '').str.strip()\n",
        "\n",
        "# Merge de datos\n",
        "merged_df = pd.merge(acreditados_df, sucursales_df, left_on='acreditadoidenti', right_on='RUC_Part2', how='inner')\n",
        "\n",
        "# Limpiar columnas de dirección\n",
        "for field in ['Ubicacion', 'Urbanizacion', 'Calle', 'Casa', 'Edificio', 'Apartamento']:\n",
        "    merged_df[field] = merged_df[field].fillna('').str.replace('NAN', '', regex=True)\n",
        "\n",
        "# Función para eliminar palabras consecutivas duplicadas dentro del texto\n",
        "def remove_duplicate_words(text):\n",
        "    words = text.split()\n",
        "    result = [words[0]] if words else []\n",
        "    for word in words[1:]:\n",
        "        if word != result[-1]:\n",
        "            result.append(word)\n",
        "    return ' '.join(result)\n",
        "\n",
        "# Función para generar dirección completa sin duplicados consecutivos de palabras\n",
        "def get_address(row):\n",
        "    parts = []\n",
        "    for field in ['Ubicacion', 'Urbanizacion', 'Calle', 'Casa', 'Edificio', 'Apartamento']:\n",
        "        value = row[field]\n",
        "        if pd.notna(value):\n",
        "            value_clean = value.strip()\n",
        "            if value_clean:\n",
        "                parts.append(value_clean)\n",
        "    address = ', '.join(parts)\n",
        "    return remove_duplicate_words(address)\n",
        "\n",
        "# Aplicar dirección completa\n",
        "merged_df['DireccionCompleta'] = merged_df.apply(get_address, axis=1)\n",
        "\n",
        "# Eliminar duplicados de RUC\n",
        "merged_df = merged_df[~merged_df.duplicated(subset=['RUC'], keep=False)]\n",
        "\n",
        "# Guardar resultado\n",
        "merged_df.to_csv('/content/merge_panamaemprende_2010_2011.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dx2ONVqH156e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "c7f082b2-41c3-4fe8-e2aa-b257be753a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'RUC_Part2'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-84f20deb2d41>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Merge de datos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmerged_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macreditados_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msucursales_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'acreditadoidenti'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RUC_Part2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Limpiar columnas de dirección\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         op = _MergeOperation(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1295\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'RUC_Part2'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PARA SACAR LOS NO COINCIDENTES\n",
        "\n",
        "acreditados_df = pd.read_csv('ACREDITADOS.csv')\n",
        "sucursales_df = pd.read_csv('DatosSucursalesLimpios.csv')\n",
        "\n",
        "acreditados_df['acreditadoidenti'] = acreditados_df['acreditadoidenti'].astype(str).str.replace('-', '').str.strip()\n",
        "\n",
        "merged_df = pd.merge(acreditados_df, sucursales_df, left_on='acreditadoidenti', right_on='RUC_Part2', how='left')\n",
        "\n",
        "merged_df['Ubicacion'] = merged_df['Ubicacion'].fillna('').str.replace('NAN','',regex=True)\n",
        "merged_df['Urbanizacion'] = merged_df['Urbanizacion'].fillna('').str.replace('NAN','',regex=True)\n",
        "merged_df['Calle'] = merged_df['Calle'].fillna('').str.replace('NAN','',regex=True)\n",
        "merged_df['Casa'] = merged_df['Casa'].fillna('').str.replace('NAN','',regex=True)\n",
        "merged_df['Edificio'] = merged_df['Edificio'].fillna('').str.replace('NAN','',regex=True)\n",
        "merged_df['Apartamento'] = merged_df['Apartamento'].fillna('').str.replace('NAN','',regex=True)\n",
        "\n",
        "def get_address(row):\n",
        "  address = \"\"\n",
        "  if row['Ubicacion'] and pd.notna(row['Ubicacion']) and row['Ubicacion'] != '':\n",
        "    address += f\"{row['Ubicacion']}, \"\n",
        "  if row['Urbanizacion'] and pd.notna(row['Urbanizacion']) and row['Urbanizacion'] != '':\n",
        "    address += f\"{row['Urbanizacion']}, \"\n",
        "  if row['Calle'] and pd.notna(row['Calle']) and row['Calle'] !='':\n",
        "      address += f\"{row['Calle']}, \"\n",
        "  if row['Casa'] and pd.notna(row['Casa']) and row['Casa'] != '':\n",
        "      address += f\"{row['Casa']}, \"\n",
        "  if row['Edificio'] and pd.notna(row['Edificio']) and row['Edificio'] != '':\n",
        "    address += f\"{row['Edificio']}, \"\n",
        "  if row['Apartamento'] and pd.notna(row['Apartamento']) and row['Apartamento'] != '':\n",
        "      address += f\"{row['Apartamento']}, \"\n",
        "  return address.strip(', ')\n",
        "\n",
        "merged_df['DireccionCompleta'] = merged_df.apply(get_address, axis=1)\n",
        "merged_df = merged_df[~merged_df.duplicated(subset=['acreditadoidenti'], keep=False)]\n",
        "\n",
        "print(merged_df.head())\n",
        "\n",
        "merged_df.to_csv('/content/datosnocruzados_panamaemprende_2024_2020.csv', index= False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_sNw2h3i-9n",
        "outputId": "65913bb7-ec19-4fb0-9ba2-fa282ac058cb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-8dd89faed668>:4: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  sucursales_df = pd.read_csv('DatosSucursalesLimpios.csv')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   acreditado_id  acreditadonum acreditadoidenti  \\\n",
            "0          42762         6397.0          3732532   \n",
            "1          25007     98534398.0          4714983   \n",
            "2          29807        26719.0          4139181   \n",
            "3          29795        80986.0         82232117   \n",
            "4          46925       102592.0          N201953   \n",
            "\n",
            "                            acreditadonom  tipopersona_id  acreditadonumcuen  \\\n",
            "0                      ADRIANO CHIN CANTO               3   5401720000118230   \n",
            "1            GUSTAVO ARIEL  ROJAS MIRANDA               1             294850   \n",
            "2                 OVIDIO  REYES RODRIGUEZ               3             425534   \n",
            "3             GUSTAVO LUIS  ARROYO DUARTE               3             287293   \n",
            "4  JACQUELINE DEL SOCORRO  ESTRADA ARANGO               3             441661   \n",
            "\n",
            "                     acrefechcre acreusucre acreipcre  \\\n",
            "0  2025-04-03 17:17:41.760 -0500      admin   0.0.0.0   \n",
            "1  2025-04-03 17:17:41.760 -0500      admin   0.0.0.0   \n",
            "2  2025-04-03 17:17:41.760 -0500      admin   0.0.0.0   \n",
            "3  2025-04-03 17:17:41.760 -0500      admin   0.0.0.0   \n",
            "4  2025-04-03 17:17:41.760 -0500      admin   0.0.0.0   \n",
            "\n",
            "                     acrefechmod  ...   Estado Unnamed15 Unnamed16 Unnamed17  \\\n",
            "0  2025-04-03 17:17:41.760 -0500  ...  VIGENTE       NaN       NaN       NaN   \n",
            "1  2025-04-03 17:17:41.760 -0500  ...      NaN       NaN       NaN       NaN   \n",
            "2  2025-04-03 17:17:41.760 -0500  ...      NaN       NaN       NaN       NaN   \n",
            "3  2025-04-03 17:17:41.760 -0500  ...      NaN       NaN       NaN       NaN   \n",
            "4  2025-04-03 17:17:41.760 -0500  ...      NaN       NaN       NaN       NaN   \n",
            "\n",
            "  Unnamed18 RUC_Part1 RUC_Part2 RUC_Part3 RUC_Part4  \\\n",
            "0       NaN       RUC   3732532        DV      59.0   \n",
            "1       NaN       NaN       NaN       NaN       NaN   \n",
            "2       NaN       NaN       NaN       NaN       NaN   \n",
            "3       NaN       NaN       NaN       NaN       NaN   \n",
            "4       NaN       NaN       NaN       NaN       NaN   \n",
            "\n",
            "                                   DireccionCompleta  \n",
            "0  CHIRIQU BAR PUERTO ARMUELLES CABECERA, MONTE V...  \n",
            "1                                                     \n",
            "2                                                     \n",
            "3                                                     \n",
            "4                                                     \n",
            "\n",
            "[5 rows x 39 columns]\n"
          ]
        }
      ]
    }
  ]
}